{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The pendulum challenge is to keep a \n",
    "frictionless pendulum standing up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# The Pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "| Num | Observation |\n",
    "|:-:|:-:|\n",
    "| 0 | cos(theta) |\n",
    "| 1 | sin(theta) |\n",
    "| 2 | theta dot |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<style>\n",
    "td {\n",
    "  font-size: 100px\n",
    "}\n",
    "    \n",
    "    \n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the state space: (3,)\n",
      "Highest value: [1. 1. 8.]\n",
      "Lowest value: [-1. -1. -8.]\n",
      "A sample state: [-0.49051192 -0.65636176  5.2461014 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the state space: {env.observation_space.shape}\")\n",
    "print(f\"Highest value: {env.observation_space.high}\")\n",
    "print(f\"Lowest value: {env.observation_space.low}\")\n",
    "\n",
    "env.observation_space\n",
    "\n",
    "print(f\"A sample state: {env.observation_space.sample()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "| Num | Action |\n",
    "|:-:|:-:|\n",
    "| 0 | Joint effort |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the action space: (1,)\n",
      "Highest value: [2.]\n",
      "Lowest value: [-2.]\n",
      "A sample action: [-0.8608973]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the action space: {env.action_space.shape}\")\n",
    "print(f\"Highest value: {env.action_space.high}\")\n",
    "print(f\"Lowest value: {env.action_space.low}\")\n",
    "\n",
    "env.action_space.seed(473)\n",
    "\n",
    "print(f\"A sample action: {env.action_space.sample()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8785995], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Function: $-(theta^2 + 0.1*thetaDot^2 + 0.001*action^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "class ScoreEvaluator:\n",
    "    def __init__(self, window: int):\n",
    "        self.window = window\n",
    "        self.best_score = -np.inf\n",
    "        self.avg_scores = []\n",
    "        self.tmp_scores = deque(maxlen=window)\n",
    "        self.last_score = None\n",
    "        \n",
    "    def add(self, score: float):\n",
    "        if not score:\n",
    "            raise ValueError(f'Score could not be {score}')\n",
    "         \n",
    "        self.tmp_scores.append(score)\n",
    "        \n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "        \n",
    "        self._update_avg()\n",
    "        self.last_score = score\n",
    "        \n",
    "    def plot_avg_scores(self):\n",
    "        plt.plot(np.linspace(0,\n",
    "                             len(self.avg_scores),\n",
    "                             len(self.avg_scores),\n",
    "                             endpoint=False),\n",
    "                 np.asarray(self.avg_scores))\n",
    "        plt.title(f'Best Reward: {self.best_score:10.5f}')\n",
    "        plt.xlabel('Episode Number')\n",
    "        plt.ylabel(f'Average Actions made (Over Next {self.window} Episodes)')\n",
    "        rolling_mean = (pd.Series(self.avg_scores)\n",
    "                          .rolling(199)\n",
    "                          .mean())\n",
    "        plt.plot(rolling_mean);\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def _update_avg(self):\n",
    "        if len(self.tmp_scores) < self.tmp_scores.maxlen:\n",
    "            return\n",
    "        self.avg_scores.append(np.mean(self.tmp_scores))\n",
    "        \n",
    "def print_iteaction(iteraction: int, score_eval: ScoreEvaluator):\n",
    "    \"function responsible to print some infos each iteration\"\n",
    "    print(\"{:4d} - Best Score: {:5.2f} - {:5.2f}\".format(iteraction,\n",
    "                                                         score_eval.best_score,\n",
    "                                                         score_eval.last_score),\n",
    "          end=\"\\r\",\n",
    "          flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "### Dummy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DummyAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def act(self, state):\n",
    "        return [np.random.normal(0., .8)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "### Policy-based Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "class PolicyAgent():\n",
    "    def __init__(self, env):\n",
    "        # Task (environment) information\n",
    "        self.env = env\n",
    "        \n",
    "        self.state_size = env.observation_space.shape[0]\n",
    "        self.action_size = env.action_space.shape[0]\n",
    "        \n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "\n",
    "        self.w = np.random.normal(\n",
    "            size=(self.state_size, self.action_size),\n",
    "            scale=(self.action_range / 10))\n",
    "\n",
    "        self.best_w1 = None\n",
    "        \n",
    "        self.best_score = -np.inf\n",
    "        \n",
    "        self.noise = 1\n",
    "        \n",
    "        self.alpha = 1e-10\n",
    "\n",
    "        self.reset_episode()\n",
    "        \n",
    "        self.find_better = 1\n",
    "        \n",
    "        self.std = self.action_range / 1000\n",
    "        \n",
    "        \n",
    "\n",
    "    def reset_episode(self):\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def step(self, next_state, reward, done, action):\n",
    "        self.total_reward += reward\n",
    "\n",
    "        self.learn(action, reward)\n",
    "#         if done:\n",
    "#             self.learn(action)\n",
    "\n",
    "    def act(self, state):\n",
    "        mean = np.dot(state, self.w)\n",
    "\n",
    "        self.last_state = state\n",
    "\n",
    "        return np.random.normal(mean, scale=self.std)\n",
    "    \n",
    "    def learn(self, action, reward):\n",
    "        grad = self._gradiant(action, np.array([self.last_state]))\n",
    "        delta = self.alpha * grad * reward\n",
    "        self.w += delta.T\n",
    "    \n",
    "    def learn_in_the_end(self, action):\n",
    "        grad = self._gradiant(action, np.array([self.last_state]))\n",
    "        delta = self.alpha * grad * self.total_reward\n",
    "\n",
    "        self.w -= delta.T\n",
    "        \n",
    "    def _gradiant(self, action, state):\n",
    "        # -1 / (5*stdÂ³)\n",
    "        cal = (-1 / (5 * self.std ** 3)) * (2*action*state - 2*state)\n",
    "        return cal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "### Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from uuid import uuid4\n",
    "\n",
    "class Buffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size: maximum size of buffer\n",
    "            batch_size: size of each training batch\n",
    "        \"\"\"\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\",\n",
    "                                     field_names=[\"session\",\n",
    "                                                  \"id\",\n",
    "                                                  \"state\",\n",
    "                                                  \"action\",\n",
    "                                                  \"reward\",\n",
    "                                                  \"next_state\",\n",
    "                                                  \"done\"])\n",
    "\n",
    "    def add(self, session, id, state, action, reward,\n",
    "            next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(session,\n",
    "                            id,\n",
    "                            state,\n",
    "                            action,\n",
    "                            reward,\n",
    "                            next_state,\n",
    "                            done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def change_reward(self, position, reward):\n",
    "        exp_temp = list(self.memory[position])\n",
    "        exp_temp[4] = reward\n",
    "        self.memory[position] = self.experience(*exp_temp)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.memory.clear()\n",
    "\n",
    "    def sample(self, batch_size=None):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        return random.sample(self.memory, k=batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "    \n",
    "    \n",
    "# testing change_reward\n",
    "x = Buffer(2,2)\n",
    "x.add(1,2,3,4,5,6,7)\n",
    "x.change_reward(0, 377)\n",
    "assert x.memory[0].reward == 377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "### Reinforce Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ReinforceAgent():\n",
    "    def __init__(self, env):\n",
    "        # Task (environment) information\n",
    "        self.env = env\n",
    "        \n",
    "        self.state_size = env.observation_space.shape[0]\n",
    "        self.action_size = env.action_space.shape[0]\n",
    "        \n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "\n",
    "        self.w = np.random.normal(\n",
    "            size=(self.state_size, self.action_size),\n",
    "            scale=(self.action_range) / 10)\n",
    "        \n",
    "        self.w2 = np.random.normal(\n",
    "            size=(self.state_size, self.action_size),\n",
    "            scale=(self.action_range) / 10)\n",
    "        \n",
    "        self.alpha = 1e-10\n",
    "   \n",
    "        self.find_better = 1\n",
    "        \n",
    "        self.std = self.action_range / 10\n",
    "        \n",
    "        self.buffer = Buffer(512, 32)\n",
    "\n",
    "        self.reset_episode()\n",
    "\n",
    "    def reset_episode(self):\n",
    "        self.cumulative_reward = 0.0\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def act(self, state):\n",
    "        mean = self._mean(state)\n",
    "        std = self._std(state)\n",
    "        action = np.random.normal(mean, scale=std)\n",
    "    \n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        \n",
    "        return mean\n",
    "    \n",
    "    \n",
    "    def step(self, next_state, reward, done):        \n",
    "        self.buffer.add(self.last_state,\n",
    "                        self.last_action,\n",
    "                        reward,\n",
    "                        next_state,\n",
    "                        done,\n",
    "                        self.cumulative_reward)\n",
    "        \n",
    "        self.cumulative_reward += reward\n",
    "\n",
    "        if done:\n",
    "            self.learn()\n",
    "\n",
    "    def learn(self):\n",
    "        for (state, action, reward, next_state,\n",
    "             done, cumulative_reward) in self.buffer.memory:\n",
    "            grad = self._gradiant(state, action).T\n",
    "            \n",
    "            self.w += (self.alpha\n",
    "                       * grad\n",
    "                       * reward)\n",
    "            \n",
    "        for (state, action, reward, next_state,\n",
    "             done, cumulative_reward) in self.buffer.sample():\n",
    "            grad = self._gradiant(state, action).T          \n",
    "\n",
    "            self.w += (self.alpha\n",
    "                       * grad\n",
    "                       * (self.cumulative_reward\n",
    "                          - cumulative_reward))   \n",
    "        \n",
    "    def _mean(self, s):\n",
    "        return np.dot(s, self.w)\n",
    "    \n",
    "    def _std(self, s):\n",
    "        return np.dot(s, self.w2)\n",
    "    \n",
    "    def _gradiant(self, s, action):\n",
    "        mean = self._mean(s)       \n",
    "        \n",
    "        cal = (s / (self.std ** 2)) * (action - mean)\n",
    "        return np.array([cal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "### Reinforce Algorithm std and Mean variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ReinforceAgentAdvanced():\n",
    "    def __init__(self, env):\n",
    "        # Task (environment) information\n",
    "        self.env = env\n",
    "        \n",
    "        self.state_size = env.observation_space.shape[0] * 3\n",
    "        self.action_size = env.action_space.shape[0]\n",
    "        \n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "\n",
    "        self.w = np.random.normal(\n",
    "            size=(self.state_size, self.action_size),\n",
    "            scale=(self.action_range) / 4)\n",
    "        \n",
    "        self.w2 = abs(np.random.normal(\n",
    "            size=(self.state_size, self.action_size),\n",
    "            scale=(self.action_range) / 4))\n",
    "        \n",
    "        self.alpha = 1e-1\n",
    "        self.gamma = 1\n",
    "   \n",
    "        self.find_better = 1\n",
    "        \n",
    "        self.all_rewards = []\n",
    "        \n",
    "        self.buffer = Buffer(30000, 192)\n",
    "        self.sample_size = 512\n",
    "\n",
    "        self.reset_episode()\n",
    "\n",
    "    def reset_episode(self):\n",
    "#         self.buffer.clear()\n",
    "        self.all_rewards.clear()\n",
    "        self.current_id = 0\n",
    "        self.session = str(uuid4().hex)\n",
    "\n",
    "    def act(self, state, explore=False):\n",
    "        if explore:\n",
    "            action = np.array([np.random.uniform(-1,1)])\n",
    "        else:\n",
    "            mean = self._mean(state)\n",
    "            std = self._std(state)\n",
    "            action = np.random.normal(mean, scale=std)\n",
    "    \n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def step(self, next_state, reward, done):\n",
    "        self.buffer.add(self.session,\n",
    "                        self.current_id,\n",
    "                        self.last_state,\n",
    "                        self.last_action,\n",
    "                        reward,\n",
    "                        next_state,\n",
    "                        done)\n",
    "        \n",
    "        self.current_id += 1\n",
    "        self.all_rewards.append(reward)\n",
    "\n",
    "        self.learn(done)\n",
    "            \n",
    "    def learn(self, done):        \n",
    "        mean_discount_reward = np.mean(self.all_rewards)\n",
    "        std_discount_reward = np.std(self.all_rewards)\n",
    "        \n",
    "        # update all rewards in buffer \n",
    "        # with cumulative normalized reward\n",
    "        if done:\n",
    "            for position, (session, id, _, _, reward, _ ,\n",
    "                           _) in enumerate(self.buffer.memory):          \n",
    "                # avoiding rows for different sessions (episodes)\n",
    "                if session != self.session:\n",
    "                    continue\n",
    "\n",
    "                # creating generator with gammas\n",
    "                dis = (self.gamma ** i for i in count(start=0, step=1))\n",
    "\n",
    "                # using the gen and the rewards to calc cumulative\n",
    "                cumulative_reward = sum([r*d for r, d\n",
    "                                         in zip(self.all_rewards[id:],\n",
    "                                                dis)])\n",
    "\n",
    "                # normalizing the cumulative reward\n",
    "                normal_rew = ((cumulative_reward - mean_discount_reward)\n",
    "                              / std_discount_reward)\n",
    "\n",
    "                # changing the reward on the buffer (using raw position)\n",
    "                self.buffer.change_reward(position, normal_rew) \n",
    "        \n",
    "        for (session, id, state, action, reward, next_state,\n",
    "             done) in self.buffer.sample(min(len(self.buffer.memory),\n",
    "                                             self.sample_size)):\n",
    "            if session != self.session:\n",
    "                continue \n",
    "                     \n",
    "            grad = self._gradiant(state, action).T \n",
    "            delta = ((1/(id+1))\n",
    "                     * grad\n",
    "                     * reward)\n",
    "            self.w += delta\n",
    "            \n",
    "            grad_2 = self._gradiant_2(state, action).T          \n",
    "            delta_2 = ((1/(id+1))\n",
    "                       * grad_2\n",
    "                       * reward)\n",
    "\n",
    "            self.w2 += delta_2\n",
    "        \n",
    "    def _mean(self, s):\n",
    "        state = np.concatenate((s, [s[0]**2, s[1]**2, s[2]**2,\n",
    "                                  s[0]*s[1], s[0]*s[2], s[1]*s[2]]))\n",
    "        return np.dot(state, self.w)\n",
    "    \n",
    "    def _std(self, s):\n",
    "        state = np.concatenate((s, [s[0]**2, s[1]**2, s[2]**2,\n",
    "                                  s[0]*s[1], s[0]*s[2], s[1]*s[2]]))\n",
    "        return abs(np.dot(state, self.w2))\n",
    "    \n",
    "    def _gradiant(self, s, action):\n",
    "        mean = self._mean(s)       \n",
    "        std = self._std(s)\n",
    "        \n",
    "        state = np.concatenate((s, [s[0]**2, s[1]**2, s[2]**2,\n",
    "                                  s[0]*s[1], s[0]*s[2], s[1]*s[2]]))\n",
    "        \n",
    "        cal = (state / (std ** 2)) * (action - mean)\n",
    "        return np.array([cal])\n",
    "    \n",
    "    def _gradiant_2(self, s, action):\n",
    "        mean = self._mean(s)       \n",
    "        std = self._std(s)\n",
    "        \n",
    "        state = np.concatenate((s, [s[0]**2, s[1]**2, s[2]**2,\n",
    "                                  s[0]*s[1], s[0]*s[2], s[1]*s[2]]))\n",
    "        \n",
    "        cal = state*(mean + std - action)*(-mean + std + action)/(std ** 3)\n",
    "        return np.array([cal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9 - Best Score: -876.23 - -876.2382\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "\n",
    "agent = ReinforceAgentAdvanced(env)\n",
    "\n",
    "best_score = -np.inf\n",
    "\n",
    "avg_scores = deque(maxlen=num_episodes)\n",
    "\n",
    "score_eval = ScoreEvaluator(1)\n",
    "\n",
    "for i in range(num_episodes):  \n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    agent.reset_episode()\n",
    "    \n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        agent.step(state, reward, done)\n",
    "        \n",
    "        score += reward\n",
    "        if done:\n",
    "            score_eval.add(score)\n",
    "            print_iteaction(i, score_eval)\n",
    "            break\n",
    "            \n",
    "score_eval.plot_avg_scores()\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for i in range(2):\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        agent.reset_episode()\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### DDPG Actor/Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size: maximum size of buffer\n",
    "            batch_size: size of each training batch\n",
    "        \"\"\"\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        return random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "    \n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, mu, theta, sigma):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class DDPGAgent():\n",
    "    \"\"\"Reinforcement Learning agent that learns using DDPG.\"\"\"\n",
    "    def __init__(self, env):  \n",
    "        self.env = env\n",
    "        self.state_size = env.observation_space.shape[0]\n",
    "        self.action_size = env.action_space.shape[0]\n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "\n",
    "        # Actor (Policy) Model\n",
    "        self.actor_local = Actor(self.state_size, self.action_size, self.action_low, self.action_high)\n",
    "        self.actor_target = Actor(self.state_size, self.action_size, self.action_low, self.action_high)\n",
    "\n",
    "        # Critic (Value) Model\n",
    "        self.critic_local = Critic(self.state_size, self.action_size)\n",
    "        self.critic_target = Critic(self.state_size, self.action_size)\n",
    "\n",
    "        # Initialize target model parameters with local model parameters\n",
    "        self.critic_target.model.set_weights(self.critic_local.model.get_weights())\n",
    "        self.actor_target.model.set_weights(self.actor_local.model.get_weights())\n",
    "\n",
    "        # Noise process\n",
    "        self.exploration_mu = 0\n",
    "        self.exploration_theta = 0.15\n",
    "        self.exploration_sigma = 0.2\n",
    "        self.noise = OUNoise(self.action_size, self.exploration_mu, self.exploration_theta, self.exploration_sigma)\n",
    "\n",
    "        # Replay memory\n",
    "        self.buffer_size = 10000\n",
    "        self.batch_size = 64\n",
    "        self.memory = ReplayBuffer(self.buffer_size, self.batch_size)\n",
    "\n",
    "        # Algorithm parameters\n",
    "        self.gamma = 0.99  # discount factor\n",
    "        self.tau = 0.01  # for soft update of target parameters\n",
    "\n",
    "    def reset_episode(self):\n",
    "        self.noise.reset()\n",
    "        self.last_state = state\n",
    "\n",
    "    def step(self, action, reward, next_state, done):\n",
    "         # Save experience / reward\n",
    "        self.memory.add(self.last_state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences)\n",
    "\n",
    "        # Roll over last state and action\n",
    "        self.last_state = next_state\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Returns actions for given state(s) as per current policy.\"\"\"\n",
    "        state = np.reshape(state, [-1, self.state_size])\n",
    "        action = self.actor_local.model.predict(state)[0]\n",
    "        return list(action + self.noise.sample())  # add some noise for exploration\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\"\"\"\n",
    "        # Convert experience tuples to separate arrays for each element (states, actions, rewards, etc.)\n",
    "        states = np.vstack([e.state for e in experiences if e is not None])\n",
    "        actions = np.array([e.action for e in experiences if e is not None]).astype(np.float32).reshape(-1, self.action_size)\n",
    "        rewards = np.array([e.reward for e in experiences if e is not None]).astype(np.float32).reshape(-1, 1)\n",
    "        dones = np.array([e.done for e in experiences if e is not None]).astype(np.uint8).reshape(-1, 1)\n",
    "        next_states = np.vstack([e.next_state for e in experiences if e is not None])\n",
    "\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        #     Q_targets_next = critic_target(next_state, actor_target(next_state))\n",
    "        actions_next = self.actor_target.model.predict_on_batch(next_states)\n",
    "        Q_targets_next = self.critic_target.model.predict_on_batch([next_states, actions_next])\n",
    "\n",
    "        # Compute Q targets for current states and train critic model (local)\n",
    "        Q_targets = rewards + self.gamma * Q_targets_next * (1 - dones)\n",
    "        self.critic_local.model.train_on_batch(x=[states, actions], y=Q_targets)\n",
    "\n",
    "        # Train actor model (local)\n",
    "        action_gradients = np.reshape(self.critic_local.get_action_gradients([states, actions, 0]), (-1, self.action_size))\n",
    "        self.actor_local.train_fn([states, action_gradients, 1])  # custom training function\n",
    "\n",
    "        # Soft-update target models\n",
    "        self.soft_update(self.critic_local.model, self.critic_target.model)\n",
    "        self.soft_update(self.actor_local.model, self.actor_target.model)   \n",
    "\n",
    "    def soft_update(self, local_model, target_model):\n",
    "        \"\"\"Soft update model parameters.\"\"\"\n",
    "        local_weights = np.array(local_model.get_weights())\n",
    "        target_weights = np.array(target_model.get_weights())\n",
    "\n",
    "        assert len(local_weights) == len(target_weights), \"Local and target model parameters must have the same size\"\n",
    "\n",
    "        new_weights = self.tau * local_weights + (1 - self.tau) * target_weights\n",
    "        target_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "### Actor-Critic method simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "from ipdb import set_trace as debug\n",
    "\n",
    "# np.random.seed(2)\n",
    "# tf.set_random_seed(2)  # reproducible\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def gaussian(x):\n",
    "    return K.exp(-K.pow(x,2))\n",
    "\n",
    "class Actor():\n",
    "    def __init__(self, env, lr=0.0001):\n",
    "        self.env = env\n",
    "        \n",
    "        self.state_size = env.observation_space.shape\n",
    "        self.action_size = env.action_space.shape[0]\n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "\n",
    "#         self.s = tf.placeholder(tf.float32, [1, n_features], \"state\")\n",
    "#         self.a = tf.placeholder(tf.float32, None, name=\"act\")\n",
    "#         self.td_error = tf.placeholder(tf.float32, None, name=\"td_error\")\n",
    "\n",
    "        states = layers.Input(shape=self.state_size, name='states')\n",
    "        \n",
    "        layer_1 = layers.Dense(\n",
    "            units=30,\n",
    "            activation='relu',\n",
    "            kernel_initializer=keras.initializers.RandomNormal(mean=.0,\n",
    "                                                               stddev=.1),\n",
    "            bias_initializer=keras.initializers.Constant(value=0.1),\n",
    "        )(states)\n",
    "        \n",
    "        median = layers.Dense(\n",
    "            units=1,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=keras.initializers.RandomNormal(mean=.0,\n",
    "                                                               stddev=.1),\n",
    "            bias_initializer=keras.initializers.Constant(value=0.1),\n",
    "        )(layer_1)\n",
    "    \n",
    "        sigma = layers.Dense(\n",
    "            units=1,\n",
    "            activation='softplus',\n",
    "            kernel_initializer=keras.initializers.RandomNormal(mean=.0,\n",
    "                                                               stddev=.1),\n",
    "            bias_initializer=keras.initializers.Constant(value=1.),\n",
    "        )(layer_1)\n",
    "        \n",
    "        combined = layers.concatenate([median, sigma])\n",
    "        \n",
    "        def gaussian(x):\n",
    "            median, sigma = tf.squeeze(x[0][0]*2), tf.squeeze(x[0][1]+0.1)\n",
    "            return K.random_normal((1,), mean=median, stddev=sigma)\n",
    "#             return np.array([np.random.normal(median, abs(sigma))], dtype=float)\n",
    "#             return tf.distributions.Normal(median, sigma)\n",
    "        \n",
    "        actions = layers.Activation(gaussian)(combined)\n",
    "        \n",
    "#         actions = layers.Lambda(gaussian)(combined)\n",
    "        \n",
    "        self.model = models.Model(inputs=[states], outputs=actions)\n",
    "        \n",
    "        # Define optimizer and compile model for training with built-in loss function\n",
    "        optimizer = optimizers.Adam(lr=1e-3)\n",
    "        self.model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "#         # Compute action gradients (derivative of Q values w.r.t. to actions)\n",
    "#         action_gradients = K.gradients(Q_values, actions)\n",
    "\n",
    "#         # Define an additional function to fetch action gradients (to be used by actor model)\n",
    "#         self.get_action_gradients = K.function(\n",
    "#             inputs=[*self.model.input, K.learning_phase()],\n",
    "#             outputs=action_gradients)\n",
    "        \n",
    "#         debug()\n",
    "        \n",
    "#         global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "#         self.action = tf.clip_by_value(self.normal_dist.sample(1),\n",
    "#                                        self.action_low,\n",
    "#                                        self.action_high)\n",
    "\n",
    "#         with tf.name_scope('exp_v'):\n",
    "#             log_prob = self.normal_dist.log_prob(self.a)  # loss without advantage\n",
    "            \n",
    "#             self.exp_v = log_prob * self.td_error  # advantage (TD_error) guided loss\n",
    "            \n",
    "#             # Add cross entropy cost to encourage exploration\n",
    "#             self.exp_v += 0.01*self.normal_dist.entropy()\n",
    "\n",
    "#         with tf.name_scope('train'):\n",
    "#             self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v, global_step)    # min(v) = max(-v)\n",
    "\n",
    "    def learn(self, state, action, td):\n",
    "        s = s[np.newaxis, :]\n",
    "        feed_dict = {self.s: s, self.a: a, self.td_error: td}\n",
    "        _, exp_v = sess.run([self.train_op, self.exp_v], feed_dict)\n",
    "        return exp_v\n",
    "\n",
    "    def act(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        return sess.run(self.action, {self.state: s})  # get probabilities for all actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.37464064]], dtype=float32), array([[1.2310231]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = Actor(env)\n",
    "act.model.predict(np.reshape([1,2,3], [-1, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-5-f66113186dff>\u001b[0m(77)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     76 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 77 \u001b[0;31m        \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     78 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.predict(np.array([1,2,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: unexpected EOF while parsing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.predict(np.array([1,2,3]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ValueError: Error when checking input: expected states to have shape (3,) but got array with shape (1,)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-32ebf244065b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mcritic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_S\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f66113186dff>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, lr)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.action = tf.clip_by_value(self.normal_dist.sample(1),\n",
      "\u001b[0;32m<ipython-input-5-f66113186dff>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, lr)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.action = tf.clip_by_value(self.normal_dist.sample(1),\n",
      "\u001b[0;32m/usr/local/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Actor-Critic with continuous action using TD-error as the Advantage, Reinforcement Learning.\n",
    "The Pendulum example (based on https://github.com/dennybritz/reinforcement-learning/blob/master/PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb)\n",
    "Cannot converge!!! oscillate!!!\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "Using:\n",
    "tensorflow r1.3\n",
    "gym 0.8.0\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "np.random.seed(2)\n",
    "tf.set_random_seed(2)  # reproducible\n",
    "\n",
    "\n",
    "class Critic(object):\n",
    "    def __init__(self, sess, n_features, lr=0.01):\n",
    "        self.sess = sess\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.s = tf.placeholder(tf.float32, [1, n_features], \"state\")\n",
    "            self.v_ = tf.placeholder(tf.float32, [1, 1], name=\"v_next\")\n",
    "            self.r = tf.placeholder(tf.float32, name='r')\n",
    "\n",
    "        with tf.variable_scope('Critic'):\n",
    "            l1 = tf.layers.dense(\n",
    "                inputs=self.s,\n",
    "                units=30,  # number of hidden units\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=tf.random_normal_initializer(0., .1),  # weights\n",
    "                bias_initializer=tf.constant_initializer(0.1),  # biases\n",
    "                name='l1'\n",
    "            )\n",
    "\n",
    "            self.v = tf.layers.dense(\n",
    "                inputs=l1,\n",
    "                units=1,  # output units\n",
    "                activation=None,\n",
    "                kernel_initializer=tf.random_normal_initializer(0., .1),  # weights\n",
    "                bias_initializer=tf.constant_initializer(0.1),  # biases\n",
    "                name='V'\n",
    "            )\n",
    "\n",
    "        with tf.variable_scope('squared_TD_error'):\n",
    "            self.td_error = tf.reduce_mean(self.r + GAMMA * self.v_ - self.v)\n",
    "            self.loss = tf.square(self.td_error)    # TD_error = (r+gamma*V_next) - V_eval\n",
    "        with tf.variable_scope('train'):\n",
    "            self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)\n",
    "\n",
    "    def learn(self, s, r, s_):\n",
    "        s, s_ = s[np.newaxis, :], s_[np.newaxis, :]\n",
    "\n",
    "        v_ = self.sess.run(self.v, {self.s: s_})\n",
    "        td_error, _ = self.sess.run([self.td_error, self.train_op],\n",
    "                                          {self.s: s, self.v_: v_, self.r: r})\n",
    "        return td_error\n",
    "\n",
    "\n",
    "OUTPUT_GRAPH = False\n",
    "MAX_EPISODE = 1000\n",
    "MAX_EP_STEPS = 200\n",
    "DISPLAY_REWARD_THRESHOLD = -100  # renders environment if total episode reward is greater then this threshold\n",
    "RENDER = False  # rendering wastes time\n",
    "GAMMA = 0.9\n",
    "LR_A = 0.001    # learning rate for actor\n",
    "LR_C = 0.01     # learning rate for critic\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "env.seed(1)  # reproducible\n",
    "env = env.unwrapped\n",
    "\n",
    "N_S = env.observation_space.shape[0]\n",
    "A_BOUND = env.action_space.high\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "actor = Actor(env, lr=LR_A)\n",
    "critic = Critic(sess, n_features=N_S, lr=LR_C)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if OUTPUT_GRAPH:\n",
    "    tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "for i_episode in range(MAX_EPISODE):\n",
    "    s = env.reset()\n",
    "    t = 0\n",
    "    ep_rs = []\n",
    "    while True:\n",
    "        if i_episode > 900:\n",
    "            env.render()\n",
    "        a = actor.choose_action(s)\n",
    "\n",
    "        s_, r, done, info = env.step(a)\n",
    "        r /= 10\n",
    "\n",
    "        td_error = critic.learn(s, r, s_)  # gradient = grad[r + gamma * V(s_) - V(s)]\n",
    "        actor.learn(s, a, td_error)  # true_gradient = grad[logPi(s,a) * td_error]\n",
    "\n",
    "        s = s_\n",
    "        t += 1\n",
    "        ep_rs.append(r)\n",
    "        if t > MAX_EP_STEPS:\n",
    "            ep_rs_sum = sum(ep_rs)\n",
    "            if 'running_reward' not in globals():\n",
    "                running_reward = ep_rs_sum\n",
    "            else:\n",
    "                running_reward = running_reward * 0.9 + ep_rs_sum * 0.1\n",
    "            if running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True  # rendering\n",
    "            print(\"episode:\", i_episode, \"  reward:\", int(running_reward))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Actor-Critic method simplified 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "from ipdb import set_trace as debug\n",
    "\n",
    "np.random.seed(37)\n",
    "tf.set_random_seed(43)  # reproducible\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "class Actor():\n",
    "    def __init__(self, env, lr=0.0001, tau=0.001):\n",
    "        self.env = env\n",
    "        \n",
    "        self.state_size = env.observation_space.shape\n",
    "        self.action_size = env.action_space.shape\n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.model, output_layer = self.build_network()\n",
    "        self.target_model, _ = self.build_network()\n",
    "        \n",
    "        # Define Loss\n",
    "        action_gradients = layers.Input(shape=self.action_size)\n",
    "        loss = K.mean(-action_gradients*output_layer)\n",
    "        \n",
    "        # Get trainable parameters and define backprop optimization.\n",
    "        adam_optimizer = optimizers.Adam(lr=self.lr)\n",
    "        train_param = adam_optimizer.get_updates(params=self.model.trainable_weights,\n",
    "                                                 loss=loss)\n",
    "        \n",
    "        # keras.backend.learning_phase() gives a flag to be passed as input\n",
    "        # to any Keras function that uses a different behavior at train time and test time.\n",
    "        self.train_fn = K.function(inputs=[self.model.input,\n",
    "                                           action_gradients,\n",
    "                                           K.learning_phase()], \n",
    "                                   outputs=[], \n",
    "                                   updates=train_param)     \n",
    "    \n",
    "    def build_network(self):\n",
    "        states = layers.Input(shape=self.state_size, name='states')\n",
    "        \n",
    "        layer_1 = layers.Dense(\n",
    "            units=256,\n",
    "            activation='relu'\n",
    "        )(states)\n",
    "        layer_1 = layers.GaussianNoise(1.0)(layer_1)\n",
    "\n",
    "        layer_2 = layers.Dense(\n",
    "            units=128,\n",
    "            activation='relu'\n",
    "        )(layer_1)\n",
    "        layer_2 = layers.GaussianNoise(1.0)(layer_2)\n",
    "\n",
    "        output = layers.Dense(self.action_size[0],\n",
    "                    activation='tanh',\n",
    "                    kernel_initializer=keras.initializers.RandomUniform())(layer_2)\n",
    "        output = layers.Lambda(lambda i: i * self.action_range)(output)\n",
    "\n",
    "        return models.Model(inputs=[states], outputs=[output]), output\n",
    "            \n",
    "    def predict(self, state):\n",
    "        prediction = self.model.predict(np.expand_dims(state, axis=0))\n",
    "        \n",
    "        return prediction[0]\n",
    "    \n",
    "    def transfer_learning(self):\n",
    "        W, target_W = self.model.get_weights(), self.target_model.get_weights()\n",
    "        for i in range(len(W)):\n",
    "            target_W[i] = self.tau * W[i] + (1 - self.tau)* target_W[i]\n",
    "        self.target_model.set_weights(target_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class Critic():\n",
    "    def __init__(self, env, lr=0.0001, tau=0.001):\n",
    "        self.env = env\n",
    "        \n",
    "        self.state_size = env.observation_space.shape\n",
    "        self.action_size = env.action_space.shape\n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.model = self.build_network()\n",
    "        self.target_model = self.build_network()\n",
    "        \n",
    "        self.grads = K.function([self.model.input[0],\n",
    "                                 self.model.input[1]],\n",
    "                                K.gradients(self.model.output,\n",
    "                                            self.model.input[1])) \n",
    "    \n",
    "    def build_network(self):\n",
    "        states = layers.Input(shape=self.state_size, name='states')\n",
    "        actions = layers.Input(shape=self.action_size, name='actions')\n",
    "        \n",
    "        layer_1 = layers.Dense(\n",
    "            units=256,\n",
    "            activation='relu'\n",
    "        )(states)\n",
    "        \n",
    "        layer_2 = layers.concatenate([layer_1, actions])\n",
    "        \n",
    "        layer_3 = layers.Dense(\n",
    "            units=128,\n",
    "            activation='relu'\n",
    "        )(layer_2)\n",
    "    \n",
    "        output = layers.Dense(\n",
    "            units=1,\n",
    "            activation='linear',\n",
    "            kernel_initializer=keras.initializers.RandomUniform()\n",
    "        )(layer_3)\n",
    "\n",
    "        model = models.Model(inputs=[states, actions], outputs=output)\n",
    "        \n",
    "        optimizer = optimizers.Adam(lr=self.lr)\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def action_gradients(self, states, actions):\n",
    "        return self.grads([states, actions])[0]\n",
    "            \n",
    "    def predict(self, state, action):\n",
    "        return self.model.predict([np.expand_dims(state, axis=0),\n",
    "                                   np.expand_dims(action, axis=0)])[0]\n",
    "    \n",
    "    def train_on_batch(self, states, actions, critic_target):\n",
    "        return self.model.train_on_batch([states, actions],\n",
    "                                         critic_target)\n",
    "    \n",
    "    def transfer_learning(self):\n",
    "        W, target_W = self.model.get_weights(), self.target_model.get_weights()\n",
    "        for i in range(len(W)):\n",
    "            target_W[i] = self.tau * W[i] + (1 - self.tau)* target_W[i]\n",
    "        self.target_model.set_weights(target_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DDPG:\n",
    "    \"\"\" Deep Deterministic Policy Gradient (DDPG) Helper Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, buffer_size = 20000, batch_size=96,\n",
    "                 gamma = 0.99, lr = 0.00005, tau = 0.001):\n",
    "        \"\"\" Initialization\n",
    "        \"\"\"\n",
    "        # Environment and A2C parameters\n",
    "        \n",
    "        self.state_size = env.observation_space.shape\n",
    "        self.action_size = env.action_space.shape\n",
    "        self.action_high = env.action_space.high\n",
    "        self.action_low = env.action_space.low\n",
    "        self.action_range = self.action_high - self.action_low\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        # Create actor and critic networks\n",
    "        self.actor = Actor(env, 0.1 * lr, tau)\n",
    "        self.critic = Critic(env, lr, tau)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = ReplayBuffer(buffer_size, batch_size)\n",
    "\n",
    "    def act(self, state):\n",
    "        self.last_state = state\n",
    "        return self.actor.predict(state)\n",
    "    \n",
    "    def step(self, action, reward, next_state, done):\n",
    "        self.memory.add(self.last_state,\n",
    "                        action,\n",
    "                        reward,\n",
    "                        next_state,\n",
    "                        done)\n",
    "\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences)\n",
    "\n",
    "    def bellman(self, rewards, q_values, dones):\n",
    "        critic_targets = np.asarray(q_values)\n",
    "        for i in range(q_values.shape[0]):\n",
    "            if dones[i]:\n",
    "                critic_targets[i] = rewards[i]\n",
    "            else:\n",
    "                critic_targets[i] = rewards[i] + self.gamma * q_values[i]\n",
    "        return critic_targets\n",
    "\n",
    "    def memorize(self, state, action, reward, done, new_state):\n",
    "        self.memory.add(state, action, reward, done, new_state)\n",
    "\n",
    "    def sample_batch(self):\n",
    "        return self.buffer.sample()\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        states = np.vstack([e.state for e in experiences if e is not None])\n",
    "        actions = (np.array([e.action for e in experiences if e is not None])\n",
    "                     .astype(np.float32))\n",
    "        rewards = (np.array([e.reward for e in experiences if e is not None])\n",
    "                     .astype(np.float32))\n",
    "        dones = (np.array([e.done for e in experiences if e is not None])\n",
    "                   .astype(np.uint8))\n",
    "        next_states = np.vstack([e.next_state for e in experiences if e is not None])\n",
    "        \n",
    "        q_values = (self.critic\n",
    "                        .target_model\n",
    "                        .predict([next_states,\n",
    "                                  self.actor\n",
    "                                      .target_model\n",
    "                                      .predict(next_states)]))\n",
    "\n",
    "        targets = self.bellman(rewards, q_values, dones)\n",
    "\n",
    "        self.critic.train_on_batch(states, actions, targets)\n",
    "\n",
    "        actions = self.actor.model.predict(states)\n",
    "        gradients = self.critic.action_gradients(states, actions)\n",
    "        \n",
    "        self.actor.train_fn([states, gradients, 1])\n",
    "        \n",
    "        self.actor.transfer_learning()\n",
    "        self.critic.transfer_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999 - Best Score: -0.70 - -1325.96651\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "\n",
    "agent = DDPG(env)\n",
    "\n",
    "best_score = -np.inf\n",
    "\n",
    "avg_scores = deque(maxlen=num_episodes)\n",
    "\n",
    "score_eval = ScoreEvaluator(1)\n",
    "\n",
    "for i in range(num_episodes):  \n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "#     agent.reset_episode()\n",
    "    \n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "#         agent.step(state, reward, done)\n",
    "        agent.step(action, reward, state, done)\n",
    "        \n",
    "        score += reward\n",
    "        if done:\n",
    "            score_eval.add(score)\n",
    "            print_iteaction(i, score_eval)\n",
    "            break\n",
    "            \n",
    "score_eval.plot_avg_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "\n",
    "for i in range(3):\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [GPU]",
   "language": "python",
   "name": "python3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
