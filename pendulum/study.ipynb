{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The pendulum challenge is to keep a \n",
    "frictionless pendulum standing up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# The Pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "| Num | Observation |\n",
    "|:-:|:-:|\n",
    "| 0 | cos(theta) |\n",
    "| 1 | sin(theta) |\n",
    "| 2 | theta dot |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<style>\n",
    "td {\n",
    "  font-size: 100px\n",
    "}\n",
    "    \n",
    "    \n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(f\"The shape of the state space: {env.observation_space.shape}\")\n",
    "print(f\"Highest value: {env.observation_space.high}\")\n",
    "print(f\"Lowest value: {env.observation_space.low}\")\n",
    "\n",
    "env.observation_space\n",
    "\n",
    "print(f\"A sample state: {env.observation_space.sample()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "| Num | Action |\n",
    "|:-:|:-:|\n",
    "| 0 | Joint effort |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(f\"The shape of the action space: {env.action_space.shape}\")\n",
    "print(f\"Highest value: {env.action_space.high}\")\n",
    "print(f\"Lowest value: {env.action_space.low}\")\n",
    "\n",
    "env.action_space.seed(473)\n",
    "\n",
    "print(f\"A sample action: {env.action_space.sample()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Function: $-(theta^2 + 0.1*thetaDot^2 + 0.001*action^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "class ScoreEvaluator:\n",
    "    def __init__(self, window: int):\n",
    "        self.window = window\n",
    "        self.best_score = -np.inf\n",
    "        self.avg_scores = []\n",
    "        self.tmp_scores = deque(maxlen=window)\n",
    "        self.last_score = None\n",
    "        \n",
    "    def add(self, score: float):\n",
    "        if not score:\n",
    "            raise ValueError(f'Score could not be {score}')\n",
    "         \n",
    "        self.tmp_scores.append(score)\n",
    "        \n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "        \n",
    "        self._update_avg()\n",
    "        self.last_score = score\n",
    "        \n",
    "    def plot_avg_scores(self):\n",
    "        plt.plot(np.linspace(0,\n",
    "                             len(self.avg_scores),\n",
    "                             len(self.avg_scores),\n",
    "                             endpoint=False),\n",
    "                 np.asarray(self.avg_scores))\n",
    "        plt.title(f'Best Reward: {self.best_score:10.5f}')\n",
    "        plt.xlabel('Episode Number')\n",
    "        plt.ylabel(f'Average Actions made (Over Next {self.window} Episodes)')\n",
    "        plt.show()\n",
    "        \n",
    "    def _update_avg(self):\n",
    "        if len(self.tmp_scores) < self.tmp_scores.maxlen:\n",
    "            return\n",
    "        self.avg_scores.append(np.mean(self.tmp_scores))\n",
    "        \n",
    "def print_iteaction(iteraction: int, score_eval: ScoreEvaluator):\n",
    "    \"function responsible to print some infos each iteration\"\n",
    "    print(\"{:4d} - Best Score: {:5.2f} - {:5.2f}\".format(iteraction,\n",
    "                                                         score_eval.best_score,\n",
    "                                                         score_eval.last_score),\n",
    "          end=\"\\r\",\n",
    "          flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Dummy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class DummyAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def act(self, state):\n",
    "        return [np.random.normal(0., .8)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "\n",
    "agent = DummyAgent()\n",
    "\n",
    "best_score = -np.inf\n",
    "\n",
    "avg_scores = deque(maxlen=num_episodes)\n",
    "\n",
    "score_eval = ScoreEvaluator(100)\n",
    "\n",
    "for i in range(num_episodes):  \n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    for _ in range(300):\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        score += reward\n",
    "        if done:\n",
    "            score_eval.add(score)\n",
    "            print_iteaction(i, score_eval)\n",
    "            break\n",
    "            \n",
    "score_eval.plot_avg_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
